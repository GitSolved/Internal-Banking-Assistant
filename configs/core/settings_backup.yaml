# The default configuration file.
# More information about configuration can be found in the documentation: https://docs.privategpt.dev/
# Syntax in `private_pgt/settings/settings.py`
server:
  env_name: ${APP_ENV:prod}
  port: ${PORT:8001}
  cors:
    enabled: true
    allow_origins: ["*"]
    allow_methods: ["*"]
    allow_headers: ["*"]
  auth:
    enabled: false
    # python -c 'import base64; print("Basic " + base64.b64encode("secret:key".encode()).decode())'
    # 'secret' is the username and 'key' is the password for basic auth by default
    # If the auth is enabled, this value must be set in the "Authorization" header of the request.
    secret: "Basic c2VjcmV0OmtleQ=="

data:
  local_ingestion:
    enabled: ${LOCAL_INGESTION_ENABLED:true}
    allow_ingest_from: ["*"]
  local_data_folder: local_data/internal_assistant

ui:
  enabled: true
  path: /
  # "RAG", "Search", "Basic", or "Summarize"
  default_mode: "RAG"
  default_chat_system_prompt: >
    You are an internal AI assistant, providing professional support and information.
    You are knowledgeable about various business operations, compliance, and best practices.
    Always provide accurate, helpful information while maintaining professional standards.
    Do not speculate or make up requirements or data.
    Focus on practical, actionable guidance for professionals.
  default_query_system_prompt: >
    You are an internal AI cybersecurity intelligence assistant, specializing in business operations, regulatory compliance, and various services. You provide expert analysis of cybersecurity documents with deep understanding of:
    
    BANKING & REGULATORY DOCUMENTS:
    - Federal banking regulations (Federal Reserve, FDIC, OCC, CFPB guidelines)
    - Compliance documentation (CRA, BSA/AML, Fair Lending, CECL, Capital Rules)
    - Risk management policies (Credit, Market, Operational, Liquidity risk)
    - Board governance materials (Meeting minutes, resolutions, strategic plans)
    - Audit reports and examination findings
    - Loan documentation and credit policies
    
    FOR BANKING POLICIES:
    - Focus on regulatory compliance requirements and deadlines
    - Highlight approval authorities and escalation processes
    - Note examination requirements and regulatory expectations
    - Emphasize risk management and internal control provisions
    - Reference applicable banking regulations by name (Reg B, Reg Z, etc.)
    
    FOR FINANCIAL DOCUMENTS:
    - Ensure accuracy of all financial data and calculations
    - Reference banking-specific metrics (ROA, ROE, Tier 1 Capital, etc.)
    - Note regulatory capital requirements and stress test implications
    - Highlight key performance indicators and variance analysis
    - Reference accounting standards (GAAP, CECL, FAS 91, etc.)
    
    FOR MEETING MINUTES & GOVERNANCE:
    - Extract key decisions, action items, and strategic initiatives
    - Identify regulatory concerns and management responses
    - Note board oversight responsibilities and committee structures
    - Highlight risk management discussions and policy changes
    
    RESPONSE LOGIC:
    1. BASIC MATH/CALCULATIONS (2+2, percentages, etc.): Answer directly, DO NOT search documents
    2. GENERAL KNOWLEDGE (definitions, concepts): Answer directly, DO NOT search documents
    3. BANKING EXPERTISE (regulatory questions): Combine your knowledge with any relevant document context
    4. DOCUMENT-SPECIFIC (policies, meeting minutes, procedures): Use document context exclusively
    
    RESPONSE FORMAT:
    - For basic questions: Provide direct, concise answers without document citations
    - For document questions: Direct Answer → Supporting Evidence → Source Citations
    - For banking expertise: Knowledge-based answer → Document support (if available)
    - Only search documents when the question is SPECIFICALLY about your bank's policies, procedures, or meeting content
  default_summarization_system_prompt: >
    Provide a comprehensive summary of the provided context information.
    The summary should cover all the key points and main ideas presented in
    the original text, while also condensing the information into a concise
    and easy-to-understand format. Please ensure that the summary includes
    relevant details and examples that support the main ideas, while avoiding
    any unnecessary information or repetition.
  delete_file_button_enabled: true
  delete_all_files_button_enabled: true

llm:
  mode: llamacpp
  prompt_style: "llama2"
  # Should be matching the selected model
  max_new_tokens: 1024
  context_window: 8192
  # Select your tokenizer. Llama-index tokenizer is the default.
  # tokenizer: local/Foundation-Sec-8B
  temperature: 0.3      # The temperature of the model. Increasing the temperature will make the model answer more creatively. A value of 0.3 is balanced for security analysis.

rag:
  similarity_top_k: 20
  #This value controls how many "top" documents the RAG returns to use in the context.
  similarity_value: 0.2
  #This value is disabled by default.  If you enable this settings, the RAG will only use articles that meet a certain percentage score.
  rerank:
    enabled: true
    model: cross-encoder/ms-marco-MiniLM-L-2-v2
    top_n: 8

summarize:
  use_async: true

clickhouse:
    host: localhost
    port: 8443
    username: admin
    password: clickhouse
    database: embeddings

llamacpp:
  llm_hf_repo_id: local/Foundation-Sec-8B
  llm_hf_model_file: Foundation-Sec-8B-q4_k_m.gguf
  tfs_z: 1.0            # Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting
  top_k: 60             # Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40)
  top_p: 0.92           # Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)
  repeat_penalty: 1.15  # Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1)
  n_threads: 8          # Increase CPU threads for 8B model
  n_batch: 128          # Larger batch size for better performance
  n_gpu_layers: 0       # CPU only - change to 35 if you have GPU
  verbose: false        # Disable verbose logging to prevent token output interference

embedding:
  # Should be matching the value above in most cases
  mode: huggingface
  ingest_mode: simple
  embed_dim: 768 # 768 is for nomic-ai/nomic-embed-text-v1.5

huggingface:
  embedding_hf_model_name: nomic-ai/nomic-embed-text-v1.5
  access_token: ${HF_TOKEN:}
  # sentence-transformers models are fully supported by HuggingFace Transformers
  # Local model requires trust_remote_code for custom architecture
  trust_remote_code: true

vectorstore:
  database: qdrant

nodestore:
  database: simple

milvus:
  uri: local_data/internal_assistant/milvus/milvus_local.db
  collection_name: milvus_db
  overwrite: false

qdrant:
  path: local_data/internal_assistant/qdrant

postgres:
  host: localhost
  port: 5432
  database: postgres
  user: postgres
  password: postgres
  schema_name: internal_assistant

sagemaker:
  llm_endpoint_name: huggingface-pytorch-tgi-inference-2023-09-25-19-53-32-140
  embedding_endpoint_name: huggingface-pytorch-inference-2023-11-03-07-41-36-479

openai:
  api_key: ${OPENAI_API_KEY:}
  model: gpt-3.5-turbo
  embedding_api_key: ${OPENAI_API_KEY:}

ollama:
  llm_model: foundation-sec:8b
  embedding_model: nomic-embed-text
  api_base: http://localhost:11434
  embedding_api_base: http://localhost:11434  # change if your embedding model runs on another ollama
  keep_alive: 5m
  request_timeout: 120.0
  autopull_models: true

azopenai:
  api_key: ${AZ_OPENAI_API_KEY:}
  azure_endpoint: ${AZ_OPENAI_ENDPOINT:}
  embedding_deployment_name: ${AZ_OPENAI_EMBEDDING_DEPLOYMENT_NAME:}
  llm_deployment_name: ${AZ_OPENAI_LLM_DEPLOYMENT_NAME:}
  api_version: "2023-05-15"
  embedding_model: text-embedding-ada-002
  llm_model: gpt-35-turbo

gemini:
  api_key: ${GOOGLE_API_KEY:}
  model: models/gemini-pro
  embedding_model: models/embedding-001
