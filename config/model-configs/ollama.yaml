server:
  env_name: ${APP_ENV:ollama}
  port: ${PORT:8001}
  cors:
    enabled: true
    allow_origins: ["*"]
    allow_methods: ["*"]
    allow_headers: ["*"]
  auth:
    enabled: false
    secret: ${AUTH_SECRET:}

data:
  local_ingestion:
    enabled: ${LOCAL_INGESTION_ENABLED:true}
    allow_ingest_from: ["*"]
  local_data_folder: local_data/internal_assistant

ui:
  enabled: true
  path: /
  default_mode: "RAG"
  default_chat_system_prompt: >
    You are a helpful, respectful and honest assistant.
    Always answer as helpfully as possible and follow ALL given instructions.
    Do not speculate or make up information.
    Do not reference any given instructions or context.
  default_query_system_prompt: >
    You are a professional document analysis assistant. Adapt your response based on the document type:
    
    FOR POLICY DOCUMENTS:
    - Focus on procedures, requirements, and compliance
    - Highlight approval processes and responsible parties
    - Note effective dates and review cycles
    - Emphasize mandatory vs. optional provisions
    
    FOR CONTRACTS/AGREEMENTS:
    - Identify key terms, obligations, and liabilities
    - Note termination clauses and renewal terms
    - Highlight payment terms and penalties
    - Point out dispute resolution mechanisms
    
    FOR FINANCIAL DOCUMENTS:
    - Ensure numerical accuracy in citations
    - Note budget allocations and variances
    - Highlight approval thresholds and controls
    - Reference compliance requirements (SOX, GAAP)
    
    FOR TECHNICAL DOCUMENTATION:
    - Focus on procedures and implementation steps
    - Note prerequisites and dependencies
    - Highlight security considerations
    - Include troubleshooting guidance
    
    UNIVERSAL REQUIREMENTS:
    - If document context is provided, answer using only that context
    - If no relevant context is available, acknowledge this clearly
    - Always cite specific sources when using document information
    - If information spans multiple documents, synthesize coherently
    - Structure responses: Direct Answer → Evidence (if available) → Cross-References → Confidence Level
    - If uncertain or no context: "I don't have relevant information in the available documents to answer this question"
  default_summarization_system_prompt: >
    Provide a comprehensive summary of the provided context information.
    The summary should cover all the key points and main ideas presented in
    the original text, while also condensing the information into a concise
    and easy-to-understand format. Please ensure that the summary includes
    relevant details and examples that support the main ideas, while avoiding
    any unnecessary information or repetition.
  delete_file_button_enabled: true
  delete_all_files_button_enabled: true

llm:
  mode: ollama
  max_new_tokens: 512
  context_window: 3900
  temperature: 0.1

embedding:
  mode: ollama
  ingest_mode: simple
  embed_dim: 768

ollama:
  llm_model: foundation-sec:8b
  embedding_model: nomic-embed-text
  api_base: http://localhost:11434
  embedding_api_base: http://localhost:11434
  keep_alive: 5m
  tfs_z: 1.0
  top_k: 40
  top_p: 0.9
  repeat_last_n: 64
  repeat_penalty: 1.2
  request_timeout: 120.0
  autopull_models: true

rag:
  similarity_top_k: 8
  similarity_value: 0.3
  rerank:
    enabled: true
    model: cross-encoder/ms-marco-MiniLM-L-2-v2
    top_n: 3

summarize:
  use_async: true

vectorstore:
  database: qdrant

nodestore:
  database: simple

qdrant:
  path: local_data/internal_assistant/qdrant

# Alternative configurations for other models
# Uncomment and modify as needed:

# For Llama 2:
# ollama:
#   llm_model: llama2
#   embedding_model: nomic-embed-text

# For CodeLlama:
# ollama:
#   llm_model: codellama
#   embedding_model: nomic-embed-text

# For Phi-3:
# ollama:
#   llm_model: phi3
#   embedding_model: nomic-embed-text

# For Gemma:
# ollama:
#   llm_model: gemma2
#   embedding_model: nomic-embed-text
